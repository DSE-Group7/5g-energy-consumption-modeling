{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSinfo = pd.read_csv('..\\..\\Dataset\\BSinfo.csv')\n",
    "CLdata = pd.read_csv('..\\..\\Dataset\\CLdata.csv')\n",
    "ECdata = pd.read_csv('..\\..\\Dataset\\ECdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>BS</th>\n",
       "      <th>CellName</th>\n",
       "      <th>load</th>\n",
       "      <th>ESMode1</th>\n",
       "      <th>ESMode2</th>\n",
       "      <th>ESMode3</th>\n",
       "      <th>ESMode4</th>\n",
       "      <th>ESMode5</th>\n",
       "      <th>ESMode6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2023 1:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>0.487936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2023 2:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>0.344468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2023 3:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>0.193766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2023 4:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>0.222383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2023 5:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>0.175436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125570</th>\n",
       "      <td>1/2/2023 19:00</td>\n",
       "      <td>B_745</td>\n",
       "      <td>Cell3</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125571</th>\n",
       "      <td>1/2/2023 20:00</td>\n",
       "      <td>B_745</td>\n",
       "      <td>Cell3</td>\n",
       "      <td>0.064962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125572</th>\n",
       "      <td>1/2/2023 21:00</td>\n",
       "      <td>B_745</td>\n",
       "      <td>Cell3</td>\n",
       "      <td>0.081865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125573</th>\n",
       "      <td>1/2/2023 22:00</td>\n",
       "      <td>B_745</td>\n",
       "      <td>Cell3</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125574</th>\n",
       "      <td>1/2/2023 23:00</td>\n",
       "      <td>B_745</td>\n",
       "      <td>Cell3</td>\n",
       "      <td>0.066212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125575 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time     BS CellName      load  ESMode1  ESMode2  ESMode3   \n",
       "0        1/1/2023 1:00    B_0    Cell0  0.487936      0.0      0.0      0.0  \\\n",
       "1        1/1/2023 2:00    B_0    Cell0  0.344468      0.0      0.0      0.0   \n",
       "2        1/1/2023 3:00    B_0    Cell0  0.193766      0.0      0.0      0.0   \n",
       "3        1/1/2023 4:00    B_0    Cell0  0.222383      0.0      0.0      0.0   \n",
       "4        1/1/2023 5:00    B_0    Cell0  0.175436      0.0      0.0      0.0   \n",
       "...                ...    ...      ...       ...      ...      ...      ...   \n",
       "125570  1/2/2023 19:00  B_745    Cell3  0.071000      0.0      0.0      0.0   \n",
       "125571  1/2/2023 20:00  B_745    Cell3  0.064962      0.0      0.0      0.0   \n",
       "125572  1/2/2023 21:00  B_745    Cell3  0.081865      0.0      0.0      0.0   \n",
       "125573  1/2/2023 22:00  B_745    Cell3  0.097615      0.0      0.0      0.0   \n",
       "125574  1/2/2023 23:00  B_745    Cell3  0.066212      0.0      0.0      0.0   \n",
       "\n",
       "        ESMode4  ESMode5  ESMode6  \n",
       "0             0      0.0      0.0  \n",
       "1             0      0.0      0.0  \n",
       "2             0      0.0      0.0  \n",
       "3             0      0.0      0.0  \n",
       "4             0      0.0      0.0  \n",
       "...         ...      ...      ...  \n",
       "125570        0      0.0      0.0  \n",
       "125571        0      0.0      0.0  \n",
       "125572        0      0.0      0.0  \n",
       "125573        0      0.0      0.0  \n",
       "125574        0      0.0      0.0  \n",
       "\n",
       "[125575 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BS</th>\n",
       "      <th>CellName</th>\n",
       "      <th>RUType</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Bandwidth</th>\n",
       "      <th>Antennas</th>\n",
       "      <th>TXpower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_0</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>Type1</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>365.000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_1</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>Type2</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>532.000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_2</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>Type1</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>365.000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_3</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>Type2</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>532.000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_4</td>\n",
       "      <td>Cell0</td>\n",
       "      <td>Type2</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>532.000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>B_925</td>\n",
       "      <td>Cell1</td>\n",
       "      <td>Type8</td>\n",
       "      <td>Mode1</td>\n",
       "      <td>697.002</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7.877728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>B_105</td>\n",
       "      <td>Cell2</td>\n",
       "      <td>Type1</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>426.980</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>B_745</td>\n",
       "      <td>Cell2</td>\n",
       "      <td>Type1</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>426.980</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>B_105</td>\n",
       "      <td>Cell3</td>\n",
       "      <td>Type1</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>426.980</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>B_745</td>\n",
       "      <td>Cell3</td>\n",
       "      <td>Type1</td>\n",
       "      <td>Mode2</td>\n",
       "      <td>426.980</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1217 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BS CellName RUType   Mode  Frequency  Bandwidth  Antennas   TXpower\n",
       "0       B_0    Cell0  Type1  Mode2    365.000         20         4  6.875934\n",
       "1       B_1    Cell0  Type2  Mode2    532.000         20         4  6.875934\n",
       "2       B_2    Cell0  Type1  Mode2    365.000         20         4  6.875934\n",
       "3       B_3    Cell0  Type2  Mode2    532.000         20         4  6.875934\n",
       "4       B_4    Cell0  Type2  Mode2    532.000         20         4  6.875934\n",
       "...     ...      ...    ...    ...        ...        ...       ...       ...\n",
       "1212  B_925    Cell1  Type8  Mode1    697.002         10         4  7.877728\n",
       "1213  B_105    Cell2  Type1  Mode2    426.980          2         2  6.877429\n",
       "1214  B_745    Cell2  Type1  Mode2    426.980          2         2  6.877429\n",
       "1215  B_105    Cell3  Type1  Mode2    426.980          2         2  6.877429\n",
       "1216  B_745    Cell3  Type1  Mode2    426.980          2         2  6.877429\n",
       "\n",
       "[1217 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>BS</th>\n",
       "      <th>Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2023 1:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>64.275037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2023 2:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>55.904335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2023 3:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>57.698057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2023 4:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>55.156951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2023 5:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>56.053812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92624</th>\n",
       "      <td>1/2/2023 17:00</td>\n",
       "      <td>B_1018</td>\n",
       "      <td>14.648729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92625</th>\n",
       "      <td>1/2/2023 18:00</td>\n",
       "      <td>B_1018</td>\n",
       "      <td>14.648729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92626</th>\n",
       "      <td>1/2/2023 21:00</td>\n",
       "      <td>B_1018</td>\n",
       "      <td>13.452915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92627</th>\n",
       "      <td>1/2/2023 22:00</td>\n",
       "      <td>B_1018</td>\n",
       "      <td>13.602392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92628</th>\n",
       "      <td>1/2/2023 23:00</td>\n",
       "      <td>B_1018</td>\n",
       "      <td>13.303438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92629 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time      BS     Energy\n",
       "0       1/1/2023 1:00     B_0  64.275037\n",
       "1       1/1/2023 2:00     B_0  55.904335\n",
       "2       1/1/2023 3:00     B_0  57.698057\n",
       "3       1/1/2023 4:00     B_0  55.156951\n",
       "4       1/1/2023 5:00     B_0  56.053812\n",
       "...               ...     ...        ...\n",
       "92624  1/2/2023 17:00  B_1018  14.648729\n",
       "92625  1/2/2023 18:00  B_1018  14.648729\n",
       "92626  1/2/2023 21:00  B_1018  13.452915\n",
       "92627  1/2/2023 22:00  B_1018  13.602392\n",
       "92628  1/2/2023 23:00  B_1018  13.303438\n",
       "\n",
       "[92629 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>BS</th>\n",
       "      <th>CellName</th>\n",
       "      <th>load</th>\n",
       "      <th>ESMode1</th>\n",
       "      <th>ESMode2</th>\n",
       "      <th>ESMode3</th>\n",
       "      <th>ESMode4</th>\n",
       "      <th>ESMode5</th>\n",
       "      <th>ESMode6</th>\n",
       "      <th>RUType</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Bandwidth</th>\n",
       "      <th>Antennas</th>\n",
       "      <th>TXpower</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2023 1:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>64.275037</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2023 2:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>55.904335</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2023 3:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>57.698057</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2023 4:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>55.156951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2023 5:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>56.053812</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125570</th>\n",
       "      <td>1/2/2023 19:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>60.837070</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125571</th>\n",
       "      <td>1/2/2023 20:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.064962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>55.904335</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125572</th>\n",
       "      <td>1/2/2023 21:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.081865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>61.883408</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125573</th>\n",
       "      <td>1/2/2023 22:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>65.470852</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125574</th>\n",
       "      <td>1/2/2023 23:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.066212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>60.538117</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125575 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time   BS  CellName      load  ESMode1  ESMode2  ESMode3   \n",
       "0        1/1/2023 1:00    0         0  0.487936      0.0      0.0      0.0  \\\n",
       "1        1/1/2023 2:00    0         0  0.344468      0.0      0.0      0.0   \n",
       "2        1/1/2023 3:00    0         0  0.193766      0.0      0.0      0.0   \n",
       "3        1/1/2023 4:00    0         0  0.222383      0.0      0.0      0.0   \n",
       "4        1/1/2023 5:00    0         0  0.175436      0.0      0.0      0.0   \n",
       "...                ...  ...       ...       ...      ...      ...      ...   \n",
       "125570  1/2/2023 19:00  745         3  0.071000      0.0      0.0      0.0   \n",
       "125571  1/2/2023 20:00  745         3  0.064962      0.0      0.0      0.0   \n",
       "125572  1/2/2023 21:00  745         3  0.081865      0.0      0.0      0.0   \n",
       "125573  1/2/2023 22:00  745         3  0.097615      0.0      0.0      0.0   \n",
       "125574  1/2/2023 23:00  745         3  0.066212      0.0      0.0      0.0   \n",
       "\n",
       "        ESMode4  ESMode5  ESMode6  RUType  Mode  Frequency  Bandwidth   \n",
       "0             0      0.0      0.0       1     2     365.00         20  \\\n",
       "1             0      0.0      0.0       1     2     365.00         20   \n",
       "2             0      0.0      0.0       1     2     365.00         20   \n",
       "3             0      0.0      0.0       1     2     365.00         20   \n",
       "4             0      0.0      0.0       1     2     365.00         20   \n",
       "...         ...      ...      ...     ...   ...        ...        ...   \n",
       "125570        0      0.0      0.0       1     2     426.98          2   \n",
       "125571        0      0.0      0.0       1     2     426.98          2   \n",
       "125572        0      0.0      0.0       1     2     426.98          2   \n",
       "125573        0      0.0      0.0       1     2     426.98          2   \n",
       "125574        0      0.0      0.0       1     2     426.98          2   \n",
       "\n",
       "        Antennas   TXpower     Energy  Hour  Month  \n",
       "0              4  6.875934  64.275037     1      1  \n",
       "1              4  6.875934  55.904335     2      1  \n",
       "2              4  6.875934  57.698057     3      1  \n",
       "3              4  6.875934  55.156951     4      1  \n",
       "4              4  6.875934  56.053812     5      1  \n",
       "...          ...       ...        ...   ...    ...  \n",
       "125570         2  6.877429  60.837070    19      2  \n",
       "125571         2  6.877429  55.904335    20      2  \n",
       "125572         2  6.877429  61.883408    21      2  \n",
       "125573         2  6.877429  65.470852    22      2  \n",
       "125574         2  6.877429  60.538117    23      2  \n",
       "\n",
       "[125575 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(CLdata, BSinfo, on=['BS', 'CellName'], how='left')\n",
    "df = pd.merge(df, ECdata, on=['Time', 'BS'], how='left')\n",
    "df['Hour'] = pd.to_datetime(df['Time'], format='%d/%m/%Y %H:%M').dt.hour\n",
    "df['Month'] = pd.to_datetime(df['Time'], format='%d/%m/%Y %H:%M').dt.month\n",
    "df['BS'] = df['BS'].str.replace('B_', '').astype(int)\n",
    "df['CellName'] = df['CellName'].str.replace('Cell', '').astype(int)\n",
    "df['RUType'] = df['RUType'].str.replace('Type', '').astype(int)\n",
    "df['Mode'] = df['Mode'].str.replace('Mode', '').astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>BS</th>\n",
       "      <th>CellName</th>\n",
       "      <th>load</th>\n",
       "      <th>ESMode1</th>\n",
       "      <th>ESMode2</th>\n",
       "      <th>ESMode6</th>\n",
       "      <th>RUType</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Bandwidth</th>\n",
       "      <th>Antennas</th>\n",
       "      <th>TXpower</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2023 1:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>64.275037</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2023 2:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>55.904335</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2023 3:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>57.698057</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2023 4:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>55.156951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2023 5:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>365.00</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>56.053812</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125570</th>\n",
       "      <td>1/2/2023 19:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>60.837070</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125571</th>\n",
       "      <td>1/2/2023 20:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.064962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>55.904335</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125572</th>\n",
       "      <td>1/2/2023 21:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.081865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>61.883408</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125573</th>\n",
       "      <td>1/2/2023 22:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>65.470852</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125574</th>\n",
       "      <td>1/2/2023 23:00</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>0.066212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>426.98</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.877429</td>\n",
       "      <td>60.538117</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125575 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time   BS  CellName      load  ESMode1  ESMode2  ESMode6   \n",
       "0        1/1/2023 1:00    0         0  0.487936      0.0      0.0      0.0  \\\n",
       "1        1/1/2023 2:00    0         0  0.344468      0.0      0.0      0.0   \n",
       "2        1/1/2023 3:00    0         0  0.193766      0.0      0.0      0.0   \n",
       "3        1/1/2023 4:00    0         0  0.222383      0.0      0.0      0.0   \n",
       "4        1/1/2023 5:00    0         0  0.175436      0.0      0.0      0.0   \n",
       "...                ...  ...       ...       ...      ...      ...      ...   \n",
       "125570  1/2/2023 19:00  745         3  0.071000      0.0      0.0      0.0   \n",
       "125571  1/2/2023 20:00  745         3  0.064962      0.0      0.0      0.0   \n",
       "125572  1/2/2023 21:00  745         3  0.081865      0.0      0.0      0.0   \n",
       "125573  1/2/2023 22:00  745         3  0.097615      0.0      0.0      0.0   \n",
       "125574  1/2/2023 23:00  745         3  0.066212      0.0      0.0      0.0   \n",
       "\n",
       "        RUType  Mode  Frequency  Bandwidth  Antennas   TXpower     Energy   \n",
       "0            1     2     365.00         20         4  6.875934  64.275037  \\\n",
       "1            1     2     365.00         20         4  6.875934  55.904335   \n",
       "2            1     2     365.00         20         4  6.875934  57.698057   \n",
       "3            1     2     365.00         20         4  6.875934  55.156951   \n",
       "4            1     2     365.00         20         4  6.875934  56.053812   \n",
       "...        ...   ...        ...        ...       ...       ...        ...   \n",
       "125570       1     2     426.98          2         2  6.877429  60.837070   \n",
       "125571       1     2     426.98          2         2  6.877429  55.904335   \n",
       "125572       1     2     426.98          2         2  6.877429  61.883408   \n",
       "125573       1     2     426.98          2         2  6.877429  65.470852   \n",
       "125574       1     2     426.98          2         2  6.877429  60.538117   \n",
       "\n",
       "        Hour  Month  \n",
       "0          1      1  \n",
       "1          2      1  \n",
       "2          3      1  \n",
       "3          4      1  \n",
       "4          5      1  \n",
       "...      ...    ...  \n",
       "125570    19      2  \n",
       "125571    20      2  \n",
       "125572    21      2  \n",
       "125573    22      2  \n",
       "125574    23      2  \n",
       "\n",
       "[125575 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.drop(['Time'], axis=1)\n",
    "df = df.drop(['ESMode3', 'ESMode4', 'ESMode5'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('..\\..\\Dataset\\df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup =  df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Score: 2.688177867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data (Assuming df is your DataFrame)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Remove rows with NaN values in the 'Energy' column\n",
    "df_clean = df.dropna(subset=['Energy'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_clean.drop(columns=['Energy'])\n",
    "y = df_clean['Energy']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.05),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=128, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on the validation set: {mse}\")\n",
    "\n",
    "# plot the history of the loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_94 (Dense)            (None, 4196)              62940     \n",
      "                                                                 \n",
      " batch_normalization_80 (Ba  (None, 4196)              16784     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 4196)              0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 2048)              8595456   \n",
      "                                                                 \n",
      " batch_normalization_81 (Ba  (None, 2048)              8192      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_82 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_83 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_84 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_85 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_86 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_87 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11489005 (43.83 MB)\n",
      "Trainable params: 11472485 (43.76 MB)\n",
      "Non-trainable params: 16520 (64.53 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "537/537 [==============================] - 123s 224ms/step - loss: 582.2782 - val_loss: 164.4330\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 117s 218ms/step - loss: 54.6598 - val_loss: 24.8345\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 119s 222ms/step - loss: 21.1195 - val_loss: 22.2711\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 117s 219ms/step - loss: 20.5176 - val_loss: 20.1908\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 117s 218ms/step - loss: 19.9298 - val_loss: 19.0718\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 118s 220ms/step - loss: 19.5470 - val_loss: 17.4394\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 118s 219ms/step - loss: 19.1565 - val_loss: 17.2244\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 118s 220ms/step - loss: 18.7278 - val_loss: 17.3655\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 119s 222ms/step - loss: 18.8104 - val_loss: 17.3568\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 119s 221ms/step - loss: 18.1603 - val_loss: 16.7173\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 120s 224ms/step - loss: 17.8558 - val_loss: 16.3707\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 120s 223ms/step - loss: 17.7510 - val_loss: 15.2386\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 119s 222ms/step - loss: 17.1913 - val_loss: 15.4623\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 124s 231ms/step - loss: 17.2046 - val_loss: 15.3587\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 120s 223ms/step - loss: 16.9893 - val_loss: 14.6965\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 16.7514 - val_loss: 15.1343\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 120s 224ms/step - loss: 16.2615 - val_loss: 14.6326\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 16.3640 - val_loss: 14.0675\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 15.9357 - val_loss: 14.0662\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 15.8595 - val_loss: 14.1901\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 15.9847 - val_loss: 14.7727\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 15.7233 - val_loss: 13.6982\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 120s 223ms/step - loss: 15.3499 - val_loss: 13.5075\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 15.3815 - val_loss: 13.4276\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 122s 226ms/step - loss: 15.4313 - val_loss: 13.5969\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 123s 228ms/step - loss: 14.9960 - val_loss: 13.2881\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 15.0062 - val_loss: 13.5265\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 14.9055 - val_loss: 12.8126\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 14.8142 - val_loss: 12.9705\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 14.9409 - val_loss: 12.6041\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 123s 228ms/step - loss: 14.6435 - val_loss: 12.6975\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 14.4125 - val_loss: 12.2744\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 14.3340 - val_loss: 12.7548\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 14.2215 - val_loss: 12.4338\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 121s 225ms/step - loss: 14.2046 - val_loss: 12.6818\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 120s 224ms/step - loss: 14.1217 - val_loss: 12.4095\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 13.9262 - val_loss: 12.1174\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 13.8658 - val_loss: 12.5666\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 124s 230ms/step - loss: 14.0329 - val_loss: 12.0410\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 121s 225ms/step - loss: 13.5362 - val_loss: 11.8785\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 13.6768 - val_loss: 12.3503\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 13.8158 - val_loss: 11.6958\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 13.8765 - val_loss: 11.6285\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 13.6943 - val_loss: 11.4063\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 123s 229ms/step - loss: 13.4107 - val_loss: 11.4969\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 13.4531 - val_loss: 11.5504\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 123s 228ms/step - loss: 13.3831 - val_loss: 11.4156\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 13.2169 - val_loss: 11.4921\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 120s 224ms/step - loss: 13.4482 - val_loss: 11.6826\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 12.9980 - val_loss: 11.5518\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 12.9884 - val_loss: 11.2085\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 13.1246 - val_loss: 11.2444\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 13.2244 - val_loss: 11.5720\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 124s 231ms/step - loss: 12.7320 - val_loss: 11.3867\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 13.0234 - val_loss: 11.1008\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 12.9873 - val_loss: 11.3936\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 13.0459 - val_loss: 11.1303\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 123s 228ms/step - loss: 12.6431 - val_loss: 10.7394\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 123s 229ms/step - loss: 12.5630 - val_loss: 11.3879\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 123s 228ms/step - loss: 12.7675 - val_loss: 11.4521\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 123s 228ms/step - loss: 12.5576 - val_loss: 11.1613\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 12.5604 - val_loss: 10.8760\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 12.5687 - val_loss: 11.3355\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 12.4191 - val_loss: 10.8277\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 123s 229ms/step - loss: 12.1669 - val_loss: 11.0315\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 12.5207 - val_loss: 10.7457\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 122s 226ms/step - loss: 12.4228 - val_loss: 10.8621\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 124s 230ms/step - loss: 12.4433 - val_loss: 10.3985\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 12.0990 - val_loss: 10.6718\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 123s 229ms/step - loss: 12.2341 - val_loss: 10.7704\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 123s 228ms/step - loss: 12.2569 - val_loss: 11.0705\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 12.2040 - val_loss: 10.5012\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 12.0257 - val_loss: 10.6898\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 12.3349 - val_loss: 10.7601\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 121s 225ms/step - loss: 12.0085 - val_loss: 10.4132\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 123s 230ms/step - loss: 12.0006 - val_loss: 10.9298\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 123s 230ms/step - loss: 11.8580 - val_loss: 10.6492\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 117s 219ms/step - loss: 12.0668 - val_loss: 10.3964\n",
      "Epoch 79/100\n",
      "537/537 [==============================] - 118s 220ms/step - loss: 11.7787 - val_loss: 10.3474\n",
      "Epoch 80/100\n",
      "537/537 [==============================] - 117s 219ms/step - loss: 12.0460 - val_loss: 11.2802\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 118s 220ms/step - loss: 11.8421 - val_loss: 10.2448\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 119s 221ms/step - loss: 12.1036 - val_loss: 10.9913\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 120s 223ms/step - loss: 11.5188 - val_loss: 10.4966\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 119s 222ms/step - loss: 11.9768 - val_loss: 10.2031\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 121s 225ms/step - loss: 11.9798 - val_loss: 10.2137\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 124s 231ms/step - loss: 12.0116 - val_loss: 10.1184\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 11.8664 - val_loss: 10.1083\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 11.7774 - val_loss: 10.1400\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 11.6769 - val_loss: 10.1431\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 121s 226ms/step - loss: 11.8086 - val_loss: 9.9928\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 123s 229ms/step - loss: 11.5335 - val_loss: 10.0526\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 11.4812 - val_loss: 10.3074\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 11.2955 - val_loss: 9.8527\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 11.6869 - val_loss: 10.8059\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 122s 227ms/step - loss: 11.5520 - val_loss: 9.8953\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 11.5990 - val_loss: 10.0482\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 11.7017 - val_loss: 10.0850\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 121s 225ms/step - loss: 11.3808 - val_loss: 10.2128\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 124s 231ms/step - loss: 11.2498 - val_loss: 9.9470\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 122s 228ms/step - loss: 11.3309 - val_loss: 9.9252\n",
      "460/460 [==============================] - 6s 13ms/step\n",
      "Mean Squared Error on the validation set: 9.925175631506018\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove rows with NaN values in the 'Energy' column\n",
    "df_clean = df.dropna(subset=['Energy'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_clean.drop(columns=['Energy'])\n",
    "y = df_clean['Energy']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4196, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.05),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=128, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on the validation set: {mse}\")\n",
    "\n",
    "# plot the history of the loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_117 (Dense)           (None, 1024)              15360     \n",
      "                                                                 \n",
      " batch_normalization_100 (B  (None, 1024)              4096      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_101 (B  (None, 512)               2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_102 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_103 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_104 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_105 (B  (None, 32)                128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 722817 (2.76 MB)\n",
      "Trainable params: 718785 (2.74 MB)\n",
      "Non-trainable params: 4032 (15.75 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "537/537 [==============================] - 18s 27ms/step - loss: 571.5392 - val_loss: 168.1357\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 12s 23ms/step - loss: 52.3730 - val_loss: 21.4389\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 12s 23ms/step - loss: 22.6565 - val_loss: 20.0969\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 21.8304 - val_loss: 20.1456\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 21.5672 - val_loss: 18.9324\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 13s 23ms/step - loss: 20.8102 - val_loss: 18.7764\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 20.5154 - val_loss: 18.3459\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 14s 26ms/step - loss: 20.3486 - val_loss: 18.6428\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 14s 26ms/step - loss: 20.1406 - val_loss: 17.6438\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 13s 25ms/step - loss: 19.9528 - val_loss: 18.2382\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 12s 23ms/step - loss: 19.7244 - val_loss: 17.5951\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 12s 23ms/step - loss: 19.5475 - val_loss: 18.7544\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 19.1930 - val_loss: 17.8532\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 19.1446 - val_loss: 16.8871\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 21s 40ms/step - loss: 18.8993 - val_loss: 17.2829\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 22s 40ms/step - loss: 18.7902 - val_loss: 17.0223\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 22s 40ms/step - loss: 18.6922 - val_loss: 16.6105\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 21s 40ms/step - loss: 18.6982 - val_loss: 16.9798\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 22s 40ms/step - loss: 18.4950 - val_loss: 16.8664\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 24s 44ms/step - loss: 18.5477 - val_loss: 15.8968\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 23s 43ms/step - loss: 18.1484 - val_loss: 16.0811\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 24s 45ms/step - loss: 18.4461 - val_loss: 16.6147\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 23s 42ms/step - loss: 18.1728 - val_loss: 16.6598\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 24s 45ms/step - loss: 18.0958 - val_loss: 16.4492\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 24s 45ms/step - loss: 17.8211 - val_loss: 15.6798\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 23s 43ms/step - loss: 17.8880 - val_loss: 16.1698\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 23s 42ms/step - loss: 17.7591 - val_loss: 15.5947\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 21s 40ms/step - loss: 17.8491 - val_loss: 15.9492\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 23s 44ms/step - loss: 17.7365 - val_loss: 15.7223\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 23s 43ms/step - loss: 17.5265 - val_loss: 15.2884\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 25s 46ms/step - loss: 17.7561 - val_loss: 15.3344\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 23s 43ms/step - loss: 17.5747 - val_loss: 15.4458\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 25s 47ms/step - loss: 17.6241 - val_loss: 15.2322\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 26s 49ms/step - loss: 17.4691 - val_loss: 15.3113\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 27s 50ms/step - loss: 17.4946 - val_loss: 15.0802\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 23s 43ms/step - loss: 17.2439 - val_loss: 15.0230\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 21s 40ms/step - loss: 17.0522 - val_loss: 15.5399\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 17s 31ms/step - loss: 17.2953 - val_loss: 15.6274\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 14s 26ms/step - loss: 17.2469 - val_loss: 14.8342\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 17.1878 - val_loss: 14.9719\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 17.0881 - val_loss: 15.0446\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 17s 32ms/step - loss: 17.0693 - val_loss: 14.7939\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 20s 37ms/step - loss: 17.0391 - val_loss: 14.9856\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 20s 38ms/step - loss: 16.9185 - val_loss: 15.2634\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 22s 40ms/step - loss: 16.7399 - val_loss: 15.3980\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 21s 39ms/step - loss: 16.8873 - val_loss: 14.6939\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 22s 40ms/step - loss: 16.6392 - val_loss: 14.7431\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 21s 38ms/step - loss: 16.6517 - val_loss: 14.5000\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 22s 41ms/step - loss: 16.7849 - val_loss: 14.6603\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 20s 38ms/step - loss: 16.8411 - val_loss: 15.1972\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 21s 39ms/step - loss: 16.6008 - val_loss: 14.4867\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 21s 39ms/step - loss: 16.5186 - val_loss: 13.9334\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 22s 41ms/step - loss: 16.7673 - val_loss: 14.1806\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 21s 40ms/step - loss: 16.4962 - val_loss: 14.7071\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 23s 43ms/step - loss: 16.5980 - val_loss: 14.3051\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 20s 37ms/step - loss: 16.4742 - val_loss: 14.1108\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 21s 38ms/step - loss: 16.4697 - val_loss: 14.3186\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 20s 37ms/step - loss: 16.3572 - val_loss: 14.2765\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 20s 38ms/step - loss: 16.1685 - val_loss: 13.9977\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 21s 39ms/step - loss: 16.2577 - val_loss: 14.6453\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 21s 40ms/step - loss: 16.3655 - val_loss: 14.1845\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 12s 23ms/step - loss: 16.1904 - val_loss: 13.8536\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 12s 22ms/step - loss: 16.4056 - val_loss: 13.9701\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 16.1780 - val_loss: 14.0782\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 12s 23ms/step - loss: 15.9607 - val_loss: 13.8207\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 12s 23ms/step - loss: 15.9968 - val_loss: 14.3200\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 12s 22ms/step - loss: 16.1168 - val_loss: 13.9890\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 15.9344 - val_loss: 14.2646\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 12s 23ms/step - loss: 16.1793 - val_loss: 13.6126\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 16.1295 - val_loss: 13.6360\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.9388 - val_loss: 13.5058\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.8840 - val_loss: 13.7627\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.9587 - val_loss: 14.1158\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 12s 21ms/step - loss: 15.7599 - val_loss: 13.9611\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.8908 - val_loss: 13.6534\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 16.0613 - val_loss: 13.6258\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.7969 - val_loss: 13.5804\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.8418 - val_loss: 13.8453\n",
      "Epoch 79/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.9322 - val_loss: 14.0669\n",
      "Epoch 80/100\n",
      "537/537 [==============================] - 12s 22ms/step - loss: 15.6880 - val_loss: 13.4302\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 13s 25ms/step - loss: 15.8235 - val_loss: 14.0812\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 22s 40ms/step - loss: 15.8547 - val_loss: 13.3781\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 21s 40ms/step - loss: 15.6769 - val_loss: 13.6048\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 21s 39ms/step - loss: 15.5746 - val_loss: 13.7040\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 21s 39ms/step - loss: 15.6430 - val_loss: 13.2661\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 14s 26ms/step - loss: 15.5400 - val_loss: 13.4885\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 15.5676 - val_loss: 13.5278\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 15.7531 - val_loss: 13.2969\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 15.5456 - val_loss: 13.4951\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 15.6651 - val_loss: 13.7993\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 13s 23ms/step - loss: 15.6310 - val_loss: 13.1312\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 12s 22ms/step - loss: 15.4308 - val_loss: 13.5485\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 12s 22ms/step - loss: 15.2766 - val_loss: 13.4777\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.5901 - val_loss: 13.2217\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 12s 21ms/step - loss: 15.5584 - val_loss: 13.3411\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.4597 - val_loss: 13.0638\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.4713 - val_loss: 13.4712\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 11s 21ms/step - loss: 15.4764 - val_loss: 13.3733\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 13s 24ms/step - loss: 15.4285 - val_loss: 13.5407\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 13s 25ms/step - loss: 15.4784 - val_loss: 13.3153\n",
      "460/460 [==============================] - 3s 5ms/step\n",
      "Mean Squared Error on the validation set: 11.336178170117172\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_clean = df.dropna(subset=['Energy'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_clean.drop(columns=['Energy'])\n",
    "y = df_clean['Energy']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.001), input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.05),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=128, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on the validation set: {mse}\")\n",
    "\n",
    "# plot the history of the loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nadil\\OneDrive\\Documents\\UoM\\Sem 5\\DSE Project\\5g-energy-consumption-modeling\\Notebooks\\Nadil\\regression-model-nn.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nadil/OneDrive/Documents/UoM/Sem%205/DSE%20Project/5g-energy-consumption-modeling/Notebooks/Nadil/regression-model-nn.ipynb#X50sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m X_valid_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_valid)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nadil/OneDrive/Documents/UoM/Sem%205/DSE%20Project/5g-energy-consumption-modeling/Notebooks/Nadil/regression-model-nn.ipynb#X50sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m model \u001b[39m=\u001b[39m build_model(input_shape\u001b[39m=\u001b[39m(X_train_scaled\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nadil/OneDrive/Documents/UoM/Sem%205/DSE%20Project/5g-energy-consumption-modeling/Notebooks/Nadil/regression-model-nn.ipynb#X50sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train_scaled, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_valid_scaled, y_valid), verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nadil/OneDrive/Documents/UoM/Sem%205/DSE%20Project/5g-energy-consumption-modeling/Notebooks/Nadil/regression-model-nn.ipynb#X50sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m valid_preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_valid_scaled)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nadil/OneDrive/Documents/UoM/Sem%205/DSE%20Project/5g-energy-consumption-modeling/Notebooks/Nadil/regression-model-nn.ipynb#X50sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m val_score \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mmean_squared_error(y_valid, valid_preds)\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "import numpy as np\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1024, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.15),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "kf = kf.split(X=X)\n",
    "\n",
    "oof_valid_preds = np.zeros(X.shape[0], )\n",
    "test_preds_list = []\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kf):\n",
    "\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "    # Standardize the features\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "    model = build_model(input_shape=(X_train_scaled.shape[1],))\n",
    "    \n",
    "    history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=128, validation_data=(X_valid_scaled, y_valid), verbose=0)\n",
    "\n",
    "    valid_preds = model.predict(X_valid_scaled).flatten()\n",
    "\n",
    "    val_score = metrics.mean_squared_error(y_valid, valid_preds)\n",
    "    oof_valid_preds[valid_idx] = valid_preds\n",
    "\n",
    "    print(\"=*\"*50)\n",
    "    print(f\"Fold : {i}\")\n",
    "    print(f\"Valid MSE: \", val_score)\n",
    "\n",
    "oof_score = metrics.mean_squared_error(y, oof_valid_preds)\n",
    "print(\"_-*\"*50)\n",
    "print(f\"OOF MSE : \", oof_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 32768)             491520    \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 32768)             131072    \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 16384)             536887296 \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 16384)             65536     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 8192)              134225920 \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 8192)              32768     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 4096)              33558528  \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 4096)              16384     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 2048)              8390656   \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 2048)              8192      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\layer_utils.py:146: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  total_memory_size += weight_shape * per_param_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 716613505 (-1428513276.00 Byte)\n",
      "Trainable params: 716482497 (-1429037308.00 Byte)\n",
      "Non-trainable params: 131008 (511.75 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data (Assuming df is your DataFrame)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Remove rows with NaN values in the 'Energy' column\n",
    "df_clean = df.dropna(subset=['Energy'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_clean.drop(columns=['Energy'])\n",
    "y = df_clean['Energy']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32768, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16384, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(8192, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(2048, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.05),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=128, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on the validation set: {mse}\")\n",
    "\n",
    "# plot the history of the loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BS</th>\n",
       "      <th>load_Cell0</th>\n",
       "      <th>load_Cell1</th>\n",
       "      <th>load_Cell2</th>\n",
       "      <th>load_Cell3</th>\n",
       "      <th>ESMode1_Cell0</th>\n",
       "      <th>ESMode1_Cell1</th>\n",
       "      <th>ESMode1_Cell2</th>\n",
       "      <th>ESMode1_Cell3</th>\n",
       "      <th>ESMode2_Cell0</th>\n",
       "      <th>...</th>\n",
       "      <th>Antennas_Cell2</th>\n",
       "      <th>Antennas_Cell3</th>\n",
       "      <th>TXpower_Cell0</th>\n",
       "      <th>TXpower_Cell1</th>\n",
       "      <th>TXpower_Cell2</th>\n",
       "      <th>TXpower_Cell3</th>\n",
       "      <th>RUType</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.071930</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>0.224170</td>\n",
       "      <td>0.10824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>0.551320</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117</td>\n",
       "      <td>0.203220</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26134</th>\n",
       "      <td>786</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26135</th>\n",
       "      <td>790</td>\n",
       "      <td>0.221300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26136</th>\n",
       "      <td>791</td>\n",
       "      <td>0.132620</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26137</th>\n",
       "      <td>792</td>\n",
       "      <td>0.264580</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26138</th>\n",
       "      <td>794</td>\n",
       "      <td>0.138851</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.128550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26139 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BS  load_Cell0  load_Cell1  load_Cell2  load_Cell3  ESMode1_Cell0   \n",
       "0      100    0.071930     0.00000         0.0         0.0            0.0  \\\n",
       "1      101    0.016970     0.00000         0.0         0.0            0.0   \n",
       "2      105    0.224170     0.10824         0.0         0.0            0.0   \n",
       "3      108    0.551320     0.00000         0.0         0.0            0.0   \n",
       "4      117    0.203220     0.00000         0.0         0.0            0.0   \n",
       "...    ...         ...         ...         ...         ...            ...   \n",
       "26134  786    0.455900     0.00000         0.0         0.0            0.0   \n",
       "26135  790    0.221300     0.00000         0.0         0.0            0.0   \n",
       "26136  791    0.132620     0.00000         0.0         0.0            0.0   \n",
       "26137  792    0.264580     0.00000         0.0         0.0            0.0   \n",
       "26138  794    0.138851     0.00000         0.0         0.0            0.0   \n",
       "\n",
       "       ESMode1_Cell1  ESMode1_Cell2  ESMode1_Cell3  ESMode2_Cell0  ...   \n",
       "0                0.0            0.0            0.0            0.0  ...  \\\n",
       "1                0.0            0.0            0.0            0.0  ...   \n",
       "2                0.0            0.0            0.0            0.0  ...   \n",
       "3                0.0            0.0            0.0            0.0  ...   \n",
       "4                0.0            0.0            0.0            0.0  ...   \n",
       "...              ...            ...            ...            ...  ...   \n",
       "26134            0.0            0.0            0.0            0.0  ...   \n",
       "26135            0.0            0.0            0.0            0.0  ...   \n",
       "26136            0.0            0.0            0.0            0.0  ...   \n",
       "26137            0.0            0.0            0.0            0.0  ...   \n",
       "26138            0.0            0.0            0.0            0.0  ...   \n",
       "\n",
       "       Antennas_Cell2  Antennas_Cell3  TXpower_Cell0  TXpower_Cell1   \n",
       "0                 0.0             0.0       6.875934       0.000000  \\\n",
       "1                 0.0             0.0       6.875934       0.000000   \n",
       "2                 0.0             0.0       6.875934       6.875934   \n",
       "3                 0.0             0.0       6.875934       0.000000   \n",
       "4                 0.0             0.0       6.427504       0.000000   \n",
       "...               ...             ...            ...            ...   \n",
       "26134             0.0             0.0       6.427504       0.000000   \n",
       "26135             0.0             0.0       6.427504       0.000000   \n",
       "26136             0.0             0.0       6.875934       0.000000   \n",
       "26137             0.0             0.0       6.427504       0.000000   \n",
       "26138             0.0             0.0       6.128550       0.000000   \n",
       "\n",
       "       TXpower_Cell2  TXpower_Cell3  RUType  Mode  Hour  Month  \n",
       "0                0.0            0.0       4     2    10      1  \n",
       "1                0.0            0.0       4     2    10      1  \n",
       "2                0.0            0.0       1     2    10      1  \n",
       "3                0.0            0.0       1     2    10      1  \n",
       "4                0.0            0.0       5     2    10      1  \n",
       "...              ...            ...     ...   ...   ...    ...  \n",
       "26134            0.0            0.0       6     2     0      8  \n",
       "26135            0.0            0.0       6     2     0      8  \n",
       "26136            0.0            0.0       4     2     0      8  \n",
       "26137            0.0            0.0       6     2     0      8  \n",
       "26138            0.0            0.0       1     2     0      8  \n",
       "\n",
       "[26139 rows x 37 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only the row that is NaN in the 'Energy' column\n",
    "\n",
    "df_pred = df[df['Energy'].isna()]\n",
    "df_pred = df_pred.drop(columns=['Energy'], axis=1)\n",
    "df_pred.reset_index(inplace=True, drop=True)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817/817 [==============================] - 5s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BS</th>\n",
       "      <th>load_Cell0</th>\n",
       "      <th>load_Cell1</th>\n",
       "      <th>load_Cell2</th>\n",
       "      <th>load_Cell3</th>\n",
       "      <th>ESMode1_Cell0</th>\n",
       "      <th>ESMode1_Cell1</th>\n",
       "      <th>ESMode1_Cell2</th>\n",
       "      <th>ESMode1_Cell3</th>\n",
       "      <th>ESMode2_Cell0</th>\n",
       "      <th>...</th>\n",
       "      <th>Antennas_Cell3</th>\n",
       "      <th>TXpower_Cell0</th>\n",
       "      <th>TXpower_Cell1</th>\n",
       "      <th>TXpower_Cell2</th>\n",
       "      <th>TXpower_Cell3</th>\n",
       "      <th>RUType</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.071930</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>19.682716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>16.702339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>0.224170</td>\n",
       "      <td>0.10824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>56.601242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>0.551320</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>56.395363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117</td>\n",
       "      <td>0.203220</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>17.249989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26134</th>\n",
       "      <td>786</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>26.159515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26135</th>\n",
       "      <td>790</td>\n",
       "      <td>0.221300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>22.623674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26136</th>\n",
       "      <td>791</td>\n",
       "      <td>0.132620</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16.356718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26137</th>\n",
       "      <td>792</td>\n",
       "      <td>0.264580</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>24.016510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26138</th>\n",
       "      <td>794</td>\n",
       "      <td>0.138851</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.128550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>37.239681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26139 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BS  load_Cell0  load_Cell1  load_Cell2  load_Cell3  ESMode1_Cell0   \n",
       "0      100    0.071930     0.00000         0.0         0.0            0.0  \\\n",
       "1      101    0.016970     0.00000         0.0         0.0            0.0   \n",
       "2      105    0.224170     0.10824         0.0         0.0            0.0   \n",
       "3      108    0.551320     0.00000         0.0         0.0            0.0   \n",
       "4      117    0.203220     0.00000         0.0         0.0            0.0   \n",
       "...    ...         ...         ...         ...         ...            ...   \n",
       "26134  786    0.455900     0.00000         0.0         0.0            0.0   \n",
       "26135  790    0.221300     0.00000         0.0         0.0            0.0   \n",
       "26136  791    0.132620     0.00000         0.0         0.0            0.0   \n",
       "26137  792    0.264580     0.00000         0.0         0.0            0.0   \n",
       "26138  794    0.138851     0.00000         0.0         0.0            0.0   \n",
       "\n",
       "       ESMode1_Cell1  ESMode1_Cell2  ESMode1_Cell3  ESMode2_Cell0  ...   \n",
       "0                0.0            0.0            0.0            0.0  ...  \\\n",
       "1                0.0            0.0            0.0            0.0  ...   \n",
       "2                0.0            0.0            0.0            0.0  ...   \n",
       "3                0.0            0.0            0.0            0.0  ...   \n",
       "4                0.0            0.0            0.0            0.0  ...   \n",
       "...              ...            ...            ...            ...  ...   \n",
       "26134            0.0            0.0            0.0            0.0  ...   \n",
       "26135            0.0            0.0            0.0            0.0  ...   \n",
       "26136            0.0            0.0            0.0            0.0  ...   \n",
       "26137            0.0            0.0            0.0            0.0  ...   \n",
       "26138            0.0            0.0            0.0            0.0  ...   \n",
       "\n",
       "       Antennas_Cell3  TXpower_Cell0  TXpower_Cell1  TXpower_Cell2   \n",
       "0                 0.0       6.875934       0.000000            0.0  \\\n",
       "1                 0.0       6.875934       0.000000            0.0   \n",
       "2                 0.0       6.875934       6.875934            0.0   \n",
       "3                 0.0       6.875934       0.000000            0.0   \n",
       "4                 0.0       6.427504       0.000000            0.0   \n",
       "...               ...            ...            ...            ...   \n",
       "26134             0.0       6.427504       0.000000            0.0   \n",
       "26135             0.0       6.427504       0.000000            0.0   \n",
       "26136             0.0       6.875934       0.000000            0.0   \n",
       "26137             0.0       6.427504       0.000000            0.0   \n",
       "26138             0.0       6.128550       0.000000            0.0   \n",
       "\n",
       "       TXpower_Cell3  RUType  Mode  Hour  Month     Energy  \n",
       "0                0.0       4     2    10      1  19.682716  \n",
       "1                0.0       4     2    10      1  16.702339  \n",
       "2                0.0       1     2    10      1  56.601242  \n",
       "3                0.0       1     2    10      1  56.395363  \n",
       "4                0.0       5     2    10      1  17.249989  \n",
       "...              ...     ...   ...   ...    ...        ...  \n",
       "26134            0.0       6     2     0      8  26.159515  \n",
       "26135            0.0       6     2     0      8  22.623674  \n",
       "26136            0.0       4     2     0      8  16.356718  \n",
       "26137            0.0       6     2     0      8  24.016510  \n",
       "26138            0.0       1     2     0      8  37.239681  \n",
       "\n",
       "[26139 rows x 38 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predic value of 'Energy' column\n",
    "\n",
    "X_pred_scaled = scaler.transform(df_pred)\n",
    "y_pred = model.predict(X_pred_scaled)\n",
    "\n",
    "# insert the predicted value to the 'Energy' column\n",
    "\n",
    "df_pred['Energy'] = y_pred\n",
    "df_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 06:00:00_B_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 11:00:00_B_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 12:00:00_B_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 13:00:00_B_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 23:00:00_B_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27486</th>\n",
       "      <td>2023-01-02 07:00:00_B_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27487</th>\n",
       "      <td>2023-01-02 08:00:00_B_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27488</th>\n",
       "      <td>2023-01-02 11:00:00_B_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27489</th>\n",
       "      <td>2023-01-02 20:00:00_B_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27490</th>\n",
       "      <td>2023-01-02 04:00:00_B_745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27491 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID\n",
       "0        2023-01-01 06:00:00_B_0\n",
       "1        2023-01-01 11:00:00_B_0\n",
       "2        2023-01-01 12:00:00_B_0\n",
       "3        2023-01-01 13:00:00_B_0\n",
       "4        2023-01-01 23:00:00_B_0\n",
       "...                          ...\n",
       "27486  2023-01-02 07:00:00_B_105\n",
       "27487  2023-01-02 08:00:00_B_105\n",
       "27488  2023-01-02 11:00:00_B_105\n",
       "27489  2023-01-02 20:00:00_B_105\n",
       "27490  2023-01-02 04:00:00_B_745\n",
       "\n",
       "[27491 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = backup.copy()\n",
    "df_submit = df_submit[df_submit['Energy'].isna()]\n",
    "df_submit.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_submit['Time'] = pd.to_datetime(df_submit['Time'])\n",
    "df_submit['ID'] = df_submit['Time'].astype(str) + '_B_' + df_submit['BS'].astype(str) \n",
    "df_submit = df_submit[['ID']]\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_submit.to_csv('..\\..\\Dataset\\submitSketch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 06:00:00_B_0</td>\n",
       "      <td>19.682716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 11:00:00_B_0</td>\n",
       "      <td>16.702339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 12:00:00_B_0</td>\n",
       "      <td>56.601242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 13:00:00_B_0</td>\n",
       "      <td>56.395363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 23:00:00_B_0</td>\n",
       "      <td>17.249989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26134</th>\n",
       "      <td>2023-01-02 19:00:00_B_1019</td>\n",
       "      <td>26.159515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26135</th>\n",
       "      <td>2023-01-02 20:00:00_B_1019</td>\n",
       "      <td>22.623674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26136</th>\n",
       "      <td>2023-01-02 21:00:00_B_1019</td>\n",
       "      <td>16.356718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26137</th>\n",
       "      <td>2023-01-02 22:00:00_B_1019</td>\n",
       "      <td>24.016510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26138</th>\n",
       "      <td>2023-01-02 23:00:00_B_1019</td>\n",
       "      <td>37.239681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26139 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID     Energy\n",
       "0         2023-01-01 06:00:00_B_0  19.682716\n",
       "1         2023-01-01 11:00:00_B_0  16.702339\n",
       "2         2023-01-01 12:00:00_B_0  56.601242\n",
       "3         2023-01-01 13:00:00_B_0  56.395363\n",
       "4         2023-01-01 23:00:00_B_0  17.249989\n",
       "...                           ...        ...\n",
       "26134  2023-01-02 19:00:00_B_1019  26.159515\n",
       "26135  2023-01-02 20:00:00_B_1019  22.623674\n",
       "26136  2023-01-02 21:00:00_B_1019  16.356718\n",
       "26137  2023-01-02 22:00:00_B_1019  24.016510\n",
       "26138  2023-01-02 23:00:00_B_1019  37.239681\n",
       "\n",
       "[26139 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join df_submit with df_pred\n",
    "\n",
    "df_sub = pd.merge(df_submit, df_pred, left_index=True, right_index=True)\n",
    "df_sub = df_sub[['ID', 'Energy']]\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26139, 2)\n"
     ]
    }
   ],
   "source": [
    "df_sub.to_csv('nn_regression_submissions\\SampleSubmission_06.csv', index=False)\n",
    "print(df_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BS</th>\n",
       "      <th>load_Cell0</th>\n",
       "      <th>load_Cell1</th>\n",
       "      <th>load_Cell2</th>\n",
       "      <th>load_Cell3</th>\n",
       "      <th>ESMode1_Cell0</th>\n",
       "      <th>ESMode1_Cell1</th>\n",
       "      <th>ESMode1_Cell2</th>\n",
       "      <th>ESMode1_Cell3</th>\n",
       "      <th>ESMode2_Cell0</th>\n",
       "      <th>...</th>\n",
       "      <th>Antennas_Cell3</th>\n",
       "      <th>TXpower_Cell0</th>\n",
       "      <th>TXpower_Cell1</th>\n",
       "      <th>TXpower_Cell2</th>\n",
       "      <th>TXpower_Cell3</th>\n",
       "      <th>RUType</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.624745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72.645740</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22.571001</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31.240658</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.071930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118763</th>\n",
       "      <td>792</td>\n",
       "      <td>0.264580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118764</th>\n",
       "      <td>793</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.427504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>18.236173</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118765</th>\n",
       "      <td>794</td>\n",
       "      <td>0.138851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.128550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118766</th>\n",
       "      <td>795</td>\n",
       "      <td>0.537426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47.234679</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118767</th>\n",
       "      <td>796</td>\n",
       "      <td>0.108940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.128550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13.452915</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118768 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BS  load_Cell0  load_Cell1  load_Cell2  load_Cell3  ESMode1_Cell0   \n",
       "0         0    0.624745         0.0         0.0         0.0            0.0  \\\n",
       "1         1    0.028090         0.0         0.0         0.0            0.0   \n",
       "2        10    0.020947         0.0         0.0         0.0            0.0   \n",
       "3       100    0.071930         0.0         0.0         0.0            0.0   \n",
       "4       101    0.016970         0.0         0.0         0.0            0.0   \n",
       "...     ...         ...         ...         ...         ...            ...   \n",
       "118763  792    0.264580         0.0         0.0         0.0            0.0   \n",
       "118764  793    0.095300         0.0         0.0         0.0            0.0   \n",
       "118765  794    0.138851         0.0         0.0         0.0            0.0   \n",
       "118766  795    0.537426         0.0         0.0         0.0            0.0   \n",
       "118767  796    0.108940         0.0         0.0         0.0            0.0   \n",
       "\n",
       "        ESMode1_Cell1  ESMode1_Cell2  ESMode1_Cell3  ESMode2_Cell0  ...   \n",
       "0                 0.0            0.0            0.0            0.0  ...  \\\n",
       "1                 0.0            0.0            0.0            0.0  ...   \n",
       "2                 0.0            0.0            0.0            0.0  ...   \n",
       "3                 0.0            0.0            0.0            0.0  ...   \n",
       "4                 0.0            0.0            0.0            0.0  ...   \n",
       "...               ...            ...            ...            ...  ...   \n",
       "118763            0.0            0.0            0.0            0.0  ...   \n",
       "118764            0.0            0.0            0.0            0.0  ...   \n",
       "118765            0.0            0.0            0.0            0.0  ...   \n",
       "118766            0.0            0.0            0.0            0.0  ...   \n",
       "118767            0.0            0.0            0.0            0.0  ...   \n",
       "\n",
       "        Antennas_Cell3  TXpower_Cell0  TXpower_Cell1  TXpower_Cell2   \n",
       "0                  0.0       6.875934            0.0            0.0  \\\n",
       "1                  0.0       6.875934            0.0            0.0   \n",
       "2                  0.0       6.875934            0.0            0.0   \n",
       "3                  0.0       6.875934            0.0            0.0   \n",
       "4                  0.0       6.875934            0.0            0.0   \n",
       "...                ...            ...            ...            ...   \n",
       "118763             0.0       6.427504            0.0            0.0   \n",
       "118764             0.0       6.427504            0.0            0.0   \n",
       "118765             0.0       6.128550            0.0            0.0   \n",
       "118766             0.0       6.875934            0.0            0.0   \n",
       "118767             0.0       6.128550            0.0            0.0   \n",
       "\n",
       "        TXpower_Cell3  RUType  Mode     Energy  Hour  Month  \n",
       "0                 0.0       1     2  72.645740    10      1  \n",
       "1                 0.0       2     2  22.571001    10      1  \n",
       "2                 0.0       1     2  31.240658    10      1  \n",
       "3                 0.0       4     2        NaN    10      1  \n",
       "4                 0.0       4     2        NaN    10      1  \n",
       "...               ...     ...   ...        ...   ...    ...  \n",
       "118763            0.0       6     2        NaN     0      8  \n",
       "118764            0.0       6     2  18.236173     0      8  \n",
       "118765            0.0       1     2        NaN     0      8  \n",
       "118766            0.0       1     2  47.234679     0      8  \n",
       "118767            0.0       4     2  13.452915     0      8  \n",
       "\n",
       "[118768 rows x 38 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(CLdata, BSinfo, on=['BS', 'CellName'], how='left')\n",
    "df = df.drop(['ESMode3', 'ESMode4', 'ESMode5'], axis=1)\n",
    "df = df.pivot(\n",
    "    index=['Time', 'BS'],\n",
    "    columns=['CellName'],\n",
    "    values=['load', 'ESMode1', 'ESMode2', 'ESMode6', 'Frequency', 'Bandwidth', 'Antennas', 'TXpower'],\n",
    ").reset_index()\n",
    "# BS\tCellName\tload\tESMode1\tESMode2\tESMode6\tRUType\tMode\tFrequency\tBandwidth\tAntennas\tTXpower\tHour\tMonth\tEnergy\n",
    "df.columns = ['_'.join([str(i) for i in x]) for x in df.columns]\n",
    "df.columns = df.columns.str.strip('_')\n",
    "df = df.merge(BSinfo.groupby('BS')[['RUType', 'Mode']].first().reset_index(), on='BS', how='left')\n",
    "\n",
    "df = pd.merge(df, ECdata, on=['Time', 'BS'], how='left')\n",
    "df['Hour'] = pd.to_datetime(df['Time'], format='%d/%m/%Y %H:%M').dt.hour\n",
    "df['Month'] = pd.to_datetime(df['Time'], format='%d/%m/%Y %H:%M').dt.month\n",
    "df['BS'] = df['BS'].str.replace('B_', '').astype(int)\n",
    "df['RUType'] = df['RUType'].str.replace('Type', '').astype(int)\n",
    "df['Mode'] = df['Mode'].str.replace('Mode', '').astype(int)\n",
    "\n",
    "col = ['load_Cell1', 'load_Cell2', 'load_Cell3', 'ESMode1_Cell1', 'ESMode1_Cell2', 'ESMode1_Cell3', 'ESMode2_Cell1', 'ESMode2_Cell2', \n",
    "       'ESMode2_Cell3', 'ESMode6_Cell1', 'ESMode6_Cell2', 'ESMode6_Cell3', 'Frequency_Cell1', 'Frequency_Cell2', 'Frequency_Cell3', \n",
    "       'Bandwidth_Cell1', 'Bandwidth_Cell2', 'Bandwidth_Cell3', 'Antennas_Cell1', 'Antennas_Cell2', 'Antennas_Cell3', 'TXpower_Cell1', \n",
    "       'TXpower_Cell2', 'TXpower_Cell3']\n",
    "df[col] = df[col].fillna(0)\n",
    "\n",
    "df.drop(['Time'], axis=1, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_131 (Dense)           (None, 1024)              38912     \n",
      "                                                                 \n",
      " batch_normalization_112 (B  (None, 1024)              4096      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_113 (B  (None, 512)               2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_114 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_115 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_116 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_117 (B  (None, 32)                128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 746369 (2.85 MB)\n",
      "Trainable params: 742337 (2.83 MB)\n",
      "Non-trainable params: 4032 (15.75 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "507/507 [==============================] - 18s 28ms/step - loss: 568.1744 - val_loss: 208.1946\n",
      "Epoch 2/100\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 60.2557 - val_loss: 19.3674\n",
      "Epoch 3/100\n",
      "507/507 [==============================] - 13s 25ms/step - loss: 18.2819 - val_loss: 19.3839\n",
      "Epoch 4/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 17.5525 - val_loss: 16.1459\n",
      "Epoch 5/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 17.0122 - val_loss: 17.9245\n",
      "Epoch 6/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 16.6816 - val_loss: 16.0098\n",
      "Epoch 7/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 16.6304 - val_loss: 17.0360\n",
      "Epoch 8/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 16.5272 - val_loss: 15.7339\n",
      "Epoch 9/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 15.9454 - val_loss: 16.0703\n",
      "Epoch 10/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 15.9943 - val_loss: 18.4301\n",
      "Epoch 11/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 15.6933 - val_loss: 15.5163\n",
      "Epoch 12/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 15.5651 - val_loss: 15.9153\n",
      "Epoch 13/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 15.1440 - val_loss: 16.7002\n",
      "Epoch 14/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 14.9010 - val_loss: 16.8082\n",
      "Epoch 15/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 14.7782 - val_loss: 16.3771\n",
      "Epoch 16/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 14.7840 - val_loss: 15.3218\n",
      "Epoch 17/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 14.2942 - val_loss: 15.0581\n",
      "Epoch 18/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 14.1965 - val_loss: 15.2445\n",
      "Epoch 19/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 14.2514 - val_loss: 14.8062\n",
      "Epoch 20/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 14.2464 - val_loss: 14.7667\n",
      "Epoch 21/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 13.9771 - val_loss: 14.8593\n",
      "Epoch 22/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 14.2653 - val_loss: 15.2351\n",
      "Epoch 23/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 13.7695 - val_loss: 14.8522\n",
      "Epoch 24/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 13.7365 - val_loss: 15.4975\n",
      "Epoch 25/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 13.6458 - val_loss: 13.7614\n",
      "Epoch 26/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 13.6282 - val_loss: 15.6408\n",
      "Epoch 27/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 13.3668 - val_loss: 13.6132\n",
      "Epoch 28/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 13.3127 - val_loss: 14.1230\n",
      "Epoch 29/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 13.5188 - val_loss: 14.5751\n",
      "Epoch 30/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 13.1899 - val_loss: 14.1168\n",
      "Epoch 31/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 13.1212 - val_loss: 12.9766\n",
      "Epoch 32/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 12.9422 - val_loss: 13.9581\n",
      "Epoch 33/100\n",
      "507/507 [==============================] - 13s 27ms/step - loss: 12.7629 - val_loss: 13.0003\n",
      "Epoch 34/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.9602 - val_loss: 13.8468\n",
      "Epoch 35/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 13.0221 - val_loss: 13.4806\n",
      "Epoch 36/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 12.6987 - val_loss: 13.4836\n",
      "Epoch 37/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.6481 - val_loss: 14.5272\n",
      "Epoch 38/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 12.6589 - val_loss: 13.2316\n",
      "Epoch 39/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.3542 - val_loss: 12.9258\n",
      "Epoch 40/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.5072 - val_loss: 13.1853\n",
      "Epoch 41/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.5746 - val_loss: 13.1039\n",
      "Epoch 42/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.3437 - val_loss: 14.2030\n",
      "Epoch 43/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.2336 - val_loss: 14.2594\n",
      "Epoch 44/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.1088 - val_loss: 12.9578\n",
      "Epoch 45/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.2246 - val_loss: 14.0144\n",
      "Epoch 46/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.2112 - val_loss: 12.7138\n",
      "Epoch 47/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.0314 - val_loss: 13.3832\n",
      "Epoch 48/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 12.0250 - val_loss: 12.4544\n",
      "Epoch 49/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.9433 - val_loss: 12.5047\n",
      "Epoch 50/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.8856 - val_loss: 12.9550\n",
      "Epoch 51/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 12.0719 - val_loss: 13.1714\n",
      "Epoch 52/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.8417 - val_loss: 12.5705\n",
      "Epoch 53/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.8883 - val_loss: 12.7447\n",
      "Epoch 54/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.9018 - val_loss: 12.1508\n",
      "Epoch 55/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.7660 - val_loss: 13.3819\n",
      "Epoch 56/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.6400 - val_loss: 13.1296\n",
      "Epoch 57/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.7548 - val_loss: 13.5393\n",
      "Epoch 58/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.5897 - val_loss: 13.0998\n",
      "Epoch 59/100\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 11.5504 - val_loss: 14.1656\n",
      "Epoch 60/100\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 11.4401 - val_loss: 13.1948\n",
      "Epoch 61/100\n",
      "507/507 [==============================] - 13s 27ms/step - loss: 11.5095 - val_loss: 12.9573\n",
      "Epoch 62/100\n",
      "507/507 [==============================] - 13s 27ms/step - loss: 11.4906 - val_loss: 13.0691\n",
      "Epoch 63/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.4910 - val_loss: 12.1575\n",
      "Epoch 64/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.3528 - val_loss: 13.1409\n",
      "Epoch 65/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.4583 - val_loss: 11.9791\n",
      "Epoch 66/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.0949 - val_loss: 12.3935\n",
      "Epoch 67/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.1967 - val_loss: 12.5809\n",
      "Epoch 68/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.2449 - val_loss: 11.8137\n",
      "Epoch 69/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.0428 - val_loss: 12.4182\n",
      "Epoch 70/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.1988 - val_loss: 11.9353\n",
      "Epoch 71/100\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 10.7928 - val_loss: 13.3698\n",
      "Epoch 72/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.2539 - val_loss: 11.4575\n",
      "Epoch 73/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.0423 - val_loss: 11.3284\n",
      "Epoch 74/100\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 10.9393 - val_loss: 11.9608\n",
      "Epoch 75/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.1740 - val_loss: 12.0026\n",
      "Epoch 76/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.0511 - val_loss: 12.2571\n",
      "Epoch 77/100\n",
      "507/507 [==============================] - 13s 27ms/step - loss: 10.9056 - val_loss: 12.4212\n",
      "Epoch 78/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.0372 - val_loss: 11.7977\n",
      "Epoch 79/100\n",
      "507/507 [==============================] - 13s 27ms/step - loss: 10.9510 - val_loss: 12.5245\n",
      "Epoch 80/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 11.0797 - val_loss: 12.3664\n",
      "Epoch 81/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.7727 - val_loss: 11.9164\n",
      "Epoch 82/100\n",
      "507/507 [==============================] - 13s 27ms/step - loss: 10.8604 - val_loss: 12.5590\n",
      "Epoch 83/100\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 10.8792 - val_loss: 12.2538\n",
      "Epoch 84/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.6733 - val_loss: 11.4288\n",
      "Epoch 85/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.8470 - val_loss: 11.3866\n",
      "Epoch 86/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.7780 - val_loss: 11.1333\n",
      "Epoch 87/100\n",
      "507/507 [==============================] - 13s 26ms/step - loss: 10.5794 - val_loss: 11.7601\n",
      "Epoch 88/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.7546 - val_loss: 10.9112\n",
      "Epoch 89/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.5767 - val_loss: 11.3043\n",
      "Epoch 90/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.4818 - val_loss: 12.3577\n",
      "Epoch 91/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.6110 - val_loss: 11.3878\n",
      "Epoch 92/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.5574 - val_loss: 11.3535\n",
      "Epoch 93/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.7425 - val_loss: 11.3344\n",
      "Epoch 94/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 10.6456 - val_loss: 11.0782\n",
      "Epoch 95/100\n",
      "507/507 [==============================] - 14s 28ms/step - loss: 10.5266 - val_loss: 10.9133\n",
      "Epoch 96/100\n",
      "507/507 [==============================] - 15s 29ms/step - loss: 10.5780 - val_loss: 11.6013\n",
      "Epoch 97/100\n",
      "507/507 [==============================] - 16s 31ms/step - loss: 10.5818 - val_loss: 11.6935\n",
      "Epoch 98/100\n",
      "507/507 [==============================] - 17s 33ms/step - loss: 10.6335 - val_loss: 11.0974\n",
      "Epoch 99/100\n",
      "507/507 [==============================] - 16s 32ms/step - loss: 10.4550 - val_loss: 10.7751\n",
      "Epoch 100/100\n",
      "507/507 [==============================] - 14s 27ms/step - loss: 10.5643 - val_loss: 10.2137\n",
      "435/435 [==============================] - 6s 11ms/step\n",
      "Mean Squared Error on the validation set: 10.213701295739053\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data (Assuming df is your DataFrame)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Remove rows with NaN values in the 'Energy' column\n",
    "df_clean = df.dropna(subset=['Energy'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_clean.drop(columns=['Energy'])\n",
    "y = df_clean['Energy']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.15),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.05),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=128, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on the validation set: {mse}\")\n",
    "\n",
    "# plot the history of the loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "537/537 [==============================] - 2s 3ms/step - loss: 129.8983 - val_loss: 32.7366\n",
      "Epoch 2/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 27.8751 - val_loss: 25.3595\n",
      "Epoch 3/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 22.4018 - val_loss: 21.7474\n",
      "Epoch 4/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 19.9408 - val_loss: 19.6828\n",
      "Epoch 5/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 18.8178 - val_loss: 18.9098\n",
      "Epoch 6/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 18.1745 - val_loss: 18.5255\n",
      "Epoch 7/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 17.7974 - val_loss: 18.2745\n",
      "Epoch 8/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 17.5291 - val_loss: 17.8382\n",
      "Epoch 9/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 17.2429 - val_loss: 17.7973\n",
      "Epoch 10/10\n",
      "537/537 [==============================] - 1s 2ms/step - loss: 17.0505 - val_loss: 17.8881\n",
      "460/460 [==============================] - 1s 1ms/step\n",
      "Mean Squared Error on the validation set: 18.65511177178853\n",
      "Mean Squared Error on the test set: 16.927824466586515\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data (Assuming df is your DataFrame)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Separate rows with NaN values in 'Energy' column\n",
    "df_nan = df[df['Energy'].isna()]\n",
    "df_clean = df.dropna(subset=['Energy'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_clean.drop(columns=['Energy'])\n",
    "y = df_clean['Energy']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_nan_scaled = scaler.transform(df_nan.drop(columns=['Energy']))\n",
    "\n",
    "# Initialize the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=128, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# # Evaluate the model on the validation set\n",
    "# y_val_pred = model.predict(X_val_scaled)\n",
    "# val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# # Predict the missing Energy values\n",
    "# predicted_energy = model.predict(X_nan_scaled)\n",
    "\n",
    "# # Insert the predicted values back into the original DataFrame\n",
    "# df.loc[df['Energy'].isna(), 'Energy'] = np.squeeze(predicted_energy)\n",
    "\n",
    "print(f\"Mean Squared Error on the validation set: {val_mse}\")\n",
    "print(f\"Mean Squared Error on the test set: {test_mse}\")\n",
    "\n",
    "# Now, df should have the missing 'Energy' values filled in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860/860 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[52.31127 ],\n",
       "       [69.453255],\n",
       "       [66.50757 ],\n",
       "       ...,\n",
       "       [58.940605],\n",
       "       [66.66067 ],\n",
       "       [55.837646]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_energy = model.predict(X_nan_scaled)\n",
    "predicted_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>BS</th>\n",
       "      <th>Energy</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 06:00:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 11:00:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 12:00:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 13:00:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 23:00:00</td>\n",
       "      <td>B_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26134</th>\n",
       "      <td>2023-01-02 19:00:00</td>\n",
       "      <td>B_1019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26135</th>\n",
       "      <td>2023-01-02 20:00:00</td>\n",
       "      <td>B_1019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26136</th>\n",
       "      <td>2023-01-02 21:00:00</td>\n",
       "      <td>B_1019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26137</th>\n",
       "      <td>2023-01-02 22:00:00</td>\n",
       "      <td>B_1019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26138</th>\n",
       "      <td>2023-01-02 23:00:00</td>\n",
       "      <td>B_1019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26139 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time      BS  Energy  w\n",
       "0      2023-01-01 06:00:00     B_0     NaN  1\n",
       "1      2023-01-01 11:00:00     B_0     NaN  1\n",
       "2      2023-01-01 12:00:00     B_0     NaN  1\n",
       "3      2023-01-01 13:00:00     B_0     NaN  1\n",
       "4      2023-01-01 23:00:00     B_0     NaN  1\n",
       "...                    ...     ...     ... ..\n",
       "26134  2023-01-02 19:00:00  B_1019     NaN  5\n",
       "26135  2023-01-02 20:00:00  B_1019     NaN  5\n",
       "26136  2023-01-02 21:00:00  B_1019     NaN  5\n",
       "26137  2023-01-02 22:00:00  B_1019     NaN  5\n",
       "26138  2023-01-02 23:00:00  B_1019     NaN  5\n",
       "\n",
       "[26139 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (27491) does not match length of index (26139)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m sub[\u001b[39m'\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(sub[\u001b[39m'\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m sub[\u001b[39m'\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39msub[\u001b[39m'\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_B_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m sub[\u001b[39m'\u001b[39m\u001b[39mBS\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m sub[\u001b[39m'\u001b[39;49m\u001b[39mEnergy\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m=\u001b[39mpredicted_energy\n\u001b[0;32m      5\u001b[0m sub\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3960\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3957\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3958\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3959\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3960\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4153\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4144\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4155\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4156\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4157\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4158\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4159\u001b[0m     ):\n\u001b[0;32m   4160\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4161\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4880\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4877\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4879\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4880\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4881\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nadil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (27491) does not match length of index (26139)"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('..\\..\\Dataset\\SampleSubmission.csv')\n",
    "sub['Time'] = pd.to_datetime(sub['Time'], format='%Y-%d-%m %H:%M:%S')\n",
    "sub['Time']=sub['Time'].apply(lambda x: x.strftime('%Y-%d-%m %H:%M:%S')).astype(str) + '_B_' + sub['BS'].astype(str)\n",
    "sub['Energy']=predicted_energy\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125575 entries, 0 to 125574\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Time       125575 non-null  object \n",
      " 1   BS         125575 non-null  object \n",
      " 2   CellName   125575 non-null  object \n",
      " 3   load       125575 non-null  float64\n",
      " 4   ESMode1    125575 non-null  float64\n",
      " 5   ESMode2    125575 non-null  float64\n",
      " 6   ESMode3    125575 non-null  float64\n",
      " 7   ESMode4    125575 non-null  int64  \n",
      " 8   ESMode5    125575 non-null  float64\n",
      " 9   ESMode6    125575 non-null  float64\n",
      " 10  RUType     125575 non-null  object \n",
      " 11  Mode       125575 non-null  object \n",
      " 12  Frequency  125575 non-null  float64\n",
      " 13  Bandwidth  125575 non-null  int64  \n",
      " 14  Antennas   125575 non-null  int64  \n",
      " 15  TXpower    125575 non-null  float64\n",
      " 16  Energy     98084 non-null   float64\n",
      "dtypes: float64(9), int64(3), object(5)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27491"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "125575-98084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
