{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=pd.read_csv('BSinfo.csv')\n",
    "cell=pd.read_csv('CLdata.csv')\n",
    "energy=pd.read_csv('ECdata.csv')\n",
    "submit=pd.read_csv(\"PCprediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "base['BS'] = base['BS'].str.replace('B_', '')\n",
    "base['CellName'] = base['CellName'].str.replace('Cell', '')\n",
    "base['RUType'] = base['RUType'].str.replace('Type', '')\n",
    "base['Mode'] = base['Mode'].str.replace('Mode', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell['BS'] = cell['BS'].str.replace('B_', '')\n",
    "cell['CellName'] = cell['CellName'].str.replace('Cell', '')\n",
    "cell['Time'] = pd.to_datetime(cell['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy['BS'] = energy['BS'].str.replace('B_', '')\n",
    "energy['Time'] = pd.to_datetime(energy['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(energy, cell, on=['Time', 'BS'], how='left')\n",
    "final = pd.merge(merged_df, base,  on=['BS', 'CellName'], how='left')\n",
    "final['Time']=final['Time'].values.astype(float).reshape(-1, 1)  # Convert datetime to float and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=final\n",
    "y=x.pop(item='Energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "linear_reg_pipe = Pipeline([\n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "poly_reg_pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "decision_tree_pipe = Pipeline([\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "random_forest_pipe = Pipeline([\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "xgb_pipe = Pipeline([\n",
    "    ('model', XGBRegressor(random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_learning_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Regression task, so no activation function\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pipe = Pipeline([\n",
    "    ('model', create_deep_learning_model(X_train_scaled.shape[1]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pipelines\n",
    "pipelines = [\n",
    "    ('Linear Regression', linear_reg_pipe),\n",
    "    ('Polynomial Regression', poly_reg_pipe),\n",
    "    ('Decision Tree', decision_tree_pipe),\n",
    "    ('Random Forest', random_forest_pipe),\n",
    "    ('XGBoost', xgb_pipe),\n",
    "    ('Neural Network', nn_pipe)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the WMAPE function\n",
    "def wmape(y_true, y_pred):\n",
    "    weights = np.abs(y_true)\n",
    "    wmape = np.sum(np.abs(y_true - y_pred) / weights) * 100.0 / np.sum(weights)\n",
    "    return wmape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "WMAPE: 0.6861249619111771\n",
      "R-squared: 0.7623472360057131\n",
      "Mean Squared Error: 48.83985266814597\n",
      "Mean Absolute Error: 5.010667001298484\n",
      "Mean MSE: 48.09380150122859\n",
      "\n",
      "Model: Polynomial Regression\n",
      "WMAPE: 0.45167802636942483\n",
      "R-squared: 0.8965102784998095\n",
      "Mean Squared Error: 21.26810000349195\n",
      "Mean Absolute Error: 3.3551680111133253\n",
      "Mean MSE: 51792048266975.9\n",
      "\n",
      "Model: Decision Tree\n",
      "WMAPE: 0.2781228871798739\n",
      "R-squared: 0.9329750836864842\n",
      "Mean Squared Error: 13.774243492180128\n",
      "Mean Absolute Error: 2.2994606809181324\n",
      "Mean MSE: 14.52273151562468\n",
      "\n",
      "Model: Random Forest\n",
      "WMAPE: 0.21345549508203698\n",
      "R-squared: 0.9635767145985283\n",
      "Mean Squared Error: 7.485323809406546\n",
      "Mean Absolute Error: 1.7359519247792952\n",
      "Mean MSE: 8.03956394677178\n",
      "\n",
      "Model: XGBoost\n",
      "WMAPE: 0.21723970619796168\n",
      "R-squared: 0.9708134271770196\n",
      "Mean Squared Error: 5.9981120884280745\n",
      "Mean Absolute Error: 1.682067036189562\n",
      "Mean MSE: 5.967338338363651\n",
      "\n",
      "2453/2453 [==============================] - 8s 3ms/step - loss: 64.4353\n",
      "614/614 [==============================] - 1s 2ms/step\n",
      "Model: Neural Network\n",
      "WMAPE: 0.4560367822503056\n",
      "R-squared: 0.882979491038568\n",
      "Mean Squared Error: 24.048802634440186\n",
      "Mean Absolute Error: 3.5008994799903936\n",
      "1962/1962 [==============================] - 11s 3ms/step - loss: 23.0103\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 23.0564\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 23.0324\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 22.5778\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 23.0786\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "Mean MSE: 21.80517453022744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model in the pipeline\n",
    "for model_name, pipe in pipelines:\n",
    "    pipe.fit(X_train_scaled, y_train)\n",
    "    y_pred = pipe.predict(X_test_scaled)\n",
    "\n",
    "    if model_name == 'Neural Network':\n",
    "        y_pred = y_pred.flatten()\n",
    "    \n",
    "    wmape_score = wmape(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"WMAPE: {wmape_score}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "    scores = cross_val_score(pipe, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    print(f\"Mean MSE: {mse_scores.mean()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "Mean MAE: 4.975656780348674\n",
      "\n",
      "Model: Polynomial Regression\n",
      "Mean MAE: 35540.090583458004\n",
      "\n",
      "Model: Decision Tree\n",
      "Mean MAE: 2.350670310107303\n",
      "\n",
      "Model: Random Forest\n",
      "Mean MAE: 1.7896239771705296\n",
      "\n",
      "Model: XGBoost\n",
      "Mean MAE: 1.6682504536880167\n",
      "\n",
      "Model: Neural Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962/1962 [==============================] - 7s 3ms/step - loss: 72.5371\n",
      "491/491 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962/1962 [==============================] - 6s 3ms/step - loss: 74.0786\n",
      "491/491 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962/1962 [==============================] - 6s 3ms/step - loss: 72.7892\n",
      "491/491 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962/1962 [==============================] - 6s 3ms/step - loss: 80.0932\n",
      "491/491 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962/1962 [==============================] - 6s 3ms/step - loss: 74.6482\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "Mean MSE: 26.985120318079243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation for each model in the pipeline\n",
    "for model_name, pipe in pipelines:\n",
    "    print(f\"Model: {model_name}\")\n",
    "    \n",
    "    if model_name == 'Neural Network':\n",
    "        # ANN requires numpy array as input\n",
    "        scores = cross_val_score(pipe, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "        mse_scores = -scores  # Convert negative MSE back to positive\n",
    "        print(f\"Mean MSE: {mse_scores.mean()}\")\n",
    "    else:\n",
    "        scores = cross_val_score(pipe, X_train_scaled, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "        mae_scores = -scores  # Convert negative MAE back to positive\n",
    "        print(f\"Mean MAE: {mae_scores.mean()}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression, Mean Score: 4.975656780348674\n",
      "Model: Polynomial Regression, Mean Score: 35540.090583458004\n",
      "Model: Decision Tree, Mean Score: 2.350670310107303\n",
      "Model: Random Forest, Mean Score: 1.7896239771705296\n",
      "Model: XGBoost, Mean Score: 1.6682504536880167\n",
      "1962/1962 [==============================] - 5s 2ms/step - loss: 22.9740\n",
      "491/491 [==============================] - 1s 3ms/step\n",
      "1962/1962 [==============================] - 4s 2ms/step - loss: 23.1169\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 23.0567\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 22.6687\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 23.0929\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "Model: Neural Network, Mean Score: 21.6491864597907\n",
      "Best Model: XGBoost, Best Score: 1.6682504536880167\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_score = float('inf')  # Initialize with a high value\n",
    "\n",
    "for model_name, pipe in pipelines:\n",
    "    if model_name == 'Neural Network':\n",
    "        scores = cross_val_score(pipe, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "        score = -scores.mean()  # Convert negative MSE back to positive\n",
    "    else:\n",
    "        scores = cross_val_score(pipe, X_train_scaled, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "        score = -scores.mean()  # Convert negative MAE back to positive\n",
    "        \n",
    "    print(f\"Model: {model_name}, Mean Score: {score}\")\n",
    "    \n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_model = model_name\n",
    "\n",
    "print(f\"Best Model: {best_model}, Best Score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression, Mean WMAPE Score: 2.697488028823642\n",
      "Model: Polynomial Regression, Mean WMAPE Score: 5391.986880562631\n",
      "Model: Decision Tree, Mean WMAPE Score: 3.094961973689344\n",
      "Model: Random Forest, Mean WMAPE Score: 3.1799287955615307\n",
      "Model: XGBoost, Mean WMAPE Score: 3.1983100271003897\n",
      "1962/1962 [==============================] - 5s 2ms/step - loss: 22.9734\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 23.0787\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 23.0958\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 2ms/step - loss: 22.6240\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "1962/1962 [==============================] - 6s 3ms/step - loss: 22.9849\n",
      "491/491 [==============================] - 1s 2ms/step\n",
      "Model: Neural Network, Mean WMAPE Score: 2.741592748773994\n",
      "Best Model: Linear Regression, Best Mean WMAPE Score: 2.697488028823642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to calculate WMAPE\n",
    "def wmape(y_true, y_pred):\n",
    "    weights = np.abs(y_true)\n",
    "    wmape = np.sum(np.abs(y_true - y_pred) / weights) * 100.0 / np.sum(weights)\n",
    "    return wmape\n",
    "\n",
    "# Initialize best model and best score\n",
    "best_model = None\n",
    "best_score = float('inf')  # Initialize with a high value\n",
    "\n",
    "for model_name, pipe in pipelines:\n",
    "    if model_name == 'Neural Network':\n",
    "        scores = cross_val_score(pipe, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "        mse_scores = -scores  # Convert negative MSE back to positive\n",
    "        wmape_scores = [wmape(y_train, y_pred) for y_pred in np.sqrt(mse_scores)]\n",
    "        score = np.mean(wmape_scores)\n",
    "    else:\n",
    "        scores = cross_val_score(pipe, X_train_scaled, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "        mae_scores = -scores  # Convert negative MAE back to positive\n",
    "        score = np.mean([wmape(y_train, y_pred) for y_pred in mae_scores])\n",
    "    \n",
    "    print(f\"Model: {model_name}, Mean WMAPE Score: {score}\")\n",
    "    \n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_model = model_name\n",
    "\n",
    "print(f\"Best Model: {best_model}, Best Mean WMAPE Score: {best_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
