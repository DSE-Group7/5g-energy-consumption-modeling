{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMAPE: 0.6861249619111771\n",
      "R-squared: 0.7623472360057131\n",
      "Mean Squared Error: 48.83985266814597\n",
      "Mean Absolute Error: 5.010667001298484\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "base=pd.read_csv('BSinfo.csv')\n",
    "cell=pd.read_csv('CLdata.csv')\n",
    "energy=pd.read_csv('ECdata.csv')\n",
    "submit=pd.read_csv(\"PCprediction.csv\")\n",
    "\n",
    "base['BS'] = base['BS'].str.replace('B_', '')\n",
    "base['CellName'] = base['CellName'].str.replace('Cell', '')\n",
    "base['RUType'] = base['RUType'].str.replace('Type', '')\n",
    "base['Mode'] = base['Mode'].str.replace('Mode', '')\n",
    "\n",
    "cell['BS'] = cell['BS'].str.replace('B_', '')\n",
    "cell['CellName'] = cell['CellName'].str.replace('Cell', '')\n",
    "cell['Time'] = pd.to_datetime(cell['Time'])\n",
    "\n",
    "energy['BS'] = energy['BS'].str.replace('B_', '')\n",
    "energy['Time'] = pd.to_datetime(energy['Time'])\n",
    "\n",
    "merged_df = pd.merge(energy, cell, on=['Time', 'BS'], how='left')\n",
    "final = pd.merge(merged_df, base,  on=['BS', 'CellName'], how='left')\n",
    "final['Time']=final['Time'].values.astype(float).reshape(-1, 1)  # Convert datetime to float and reshape\n",
    "\n",
    "x=final\n",
    "y=x.pop(item='Energy')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Now X_train_scaled and X_test_scaled are scaled versions of the training and testing data\n",
    "\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the target variable for the scaled testing data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the Weighted Mean Absolute Percentage Error (WMAPE)\n",
    "def wmape(y_true, y_pred):\n",
    "    weights = np.abs(y_true)\n",
    "    wmape = np.sum(np.abs(y_true - y_pred) / weights) * 100.0 / np.sum(weights)\n",
    "    return wmape\n",
    "\n",
    "wmape_score = wmape(y_test, y_pred)\n",
    "print(\"WMAPE:\", wmape_score)\n",
    "\n",
    "# Calculate the R-squared (R2) score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMAPE: 0.2781228871798739\n",
      "R-squared: 0.9329750836864842\n",
      "Mean Squared Error: 13.774243492180128\n",
      "Mean Absolute Error: 2.2994606809181324\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "base=pd.read_csv('BSinfo.csv')\n",
    "cell=pd.read_csv('CLdata.csv')\n",
    "energy=pd.read_csv('ECdata.csv')\n",
    "submit=pd.read_csv(\"PCprediction.csv\")\n",
    "\n",
    "base['BS'] = base['BS'].str.replace('B_', '')\n",
    "base['CellName'] = base['CellName'].str.replace('Cell', '')\n",
    "base['RUType'] = base['RUType'].str.replace('Type', '')\n",
    "base['Mode'] = base['Mode'].str.replace('Mode', '')\n",
    "\n",
    "cell['BS'] = cell['BS'].str.replace('B_', '')\n",
    "cell['CellName'] = cell['CellName'].str.replace('Cell', '')\n",
    "cell['Time'] = pd.to_datetime(cell['Time'])\n",
    "\n",
    "energy['BS'] = energy['BS'].str.replace('B_', '')\n",
    "energy['Time'] = pd.to_datetime(energy['Time'])\n",
    "\n",
    "merged_df = pd.merge(energy, cell, on=['Time', 'BS'], how='left')\n",
    "final = pd.merge(merged_df, base,  on=['BS', 'CellName'], how='left')\n",
    "final['Time']=final['Time'].values.astype(float).reshape(-1, 1)  # Convert datetime to float and reshape\n",
    "\n",
    "x=final\n",
    "y=x.pop(item='Energy')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Now X_train_scaled and X_test_scaled are scaled versions of the training and testing data\n",
    "\n",
    "\n",
    "# Create a Decision Tree Regressor model\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the target variable for the scaled testing data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the Weighted Mean Absolute Percentage Error (WMAPE)\n",
    "def wmape(y_true, y_pred):\n",
    "    weights = np.abs(y_true)\n",
    "    wmape = np.sum(np.abs(y_true - y_pred) / weights) * 100.0 / np.sum(weights)\n",
    "    return wmape\n",
    "\n",
    "wmape_score = wmape(y_test, y_pred)\n",
    "print(\"WMAPE:\", wmape_score)\n",
    "\n",
    "# Calculate the R-squared (R2) score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "base = pd.read_csv('BSinfo.csv')\n",
    "cell = pd.read_csv('CLdata.csv')\n",
    "energy = pd.read_csv('ECdata.csv')\n",
    "submit = pd.read_csv(\"PCprediction.csv\")\n",
    "\n",
    "base['BS'] = base['BS'].str.replace('B_', '')\n",
    "base['CellName'] = base['CellName'].str.replace('Cell', '')\n",
    "base['RUType'] = base['RUType'].str.replace('Type', '')\n",
    "base['Mode'] = base['Mode'].str.replace('Mode', '')\n",
    "\n",
    "cell['BS'] = cell['BS'].str.replace('B_', '')\n",
    "cell['CellName'] = cell['CellName'].str.replace('Cell', '')\n",
    "cell['Time'] = pd.to_datetime(cell['Time'])\n",
    "\n",
    "energy['BS'] = energy['BS'].str.replace('B_', '')\n",
    "energy['Time'] = pd.to_datetime(energy['Time'])\n",
    "\n",
    "merged_df = pd.merge(energy, cell, on=['Time', 'BS'], how='left')\n",
    "final = pd.merge(merged_df, base, on=['BS', 'CellName'], how='left')\n",
    "final['Time'] = final['Time'].values.astype(float).reshape(-1, 1)  # Convert datetime to float and reshape\n",
    "print(final.dtypes)\n",
    "# Convert specified columns from object to int\n",
    "int_columns = ['BS', 'CellName', 'RUType', 'Mode']\n",
    "final[int_columns] = final[int_columns].astype(int)\n",
    "\n",
    "\n",
    "submit['Time'] = pd.to_datetime(submit['Time'])\n",
    "print(submit.shape)\n",
    "submit.drop(['w'], axis=1, inplace=True)\n",
    "# Create the 'ID' column by joining 'Time' and 'BS' columns\n",
    "submit['ID'] = submit['Time'].astype(str) + '_' + submit['BS']\n",
    "submit['BS'] = submit['BS'].str.replace('B_', '')\n",
    "submit['Time'] = submit['Time'].values.astype(float).reshape(-1, 1)  # Convert datetime to float and reshape\n",
    "submit['BS'] = submit['BS'].astype(int)\n",
    "submit = submit[['ID', 'Time', 'BS', 'Energy']]\n",
    "test = submit[['ID', 'Time', 'BS', 'Energy']]\n",
    "\n",
    "numeric_cols = ['CellName', 'load', 'ESMode1', 'ESMode2', 'ESMode3',\n",
    "                'ESMode4', 'ESMode5', 'ESMode6', 'RUType', 'Mode', 'Frequency',\n",
    "                'Bandwidth', 'Antennas', 'TXpower']\n",
    "# grouped_df = final.groupby([\"BS\"])[numeric_cols].median().reset_index()\n",
    "def calculate_median(group):\n",
    "    numeric_group = group[numeric_cols]\n",
    "    return pd.Series(np.median(numeric_group), index=numeric_cols)\n",
    "\n",
    "grouped_df = final.groupby(\"BS\")[numeric_cols].apply(calculate_median).reset_index()\n",
    "\n",
    "print(grouped_df.shape)\n",
    "grouped_df\n",
    "\n",
    "# Merge 'test' with 'final' (excluding 'Time' column) on the 'BS' column using a left join\n",
    "merged_df = test.merge(grouped_df, on='BS', how='left')\n",
    "\n",
    "# Find median values for each column (excluding 'Time') in 'final' DataFrame\n",
    "median_values = grouped_df.median()\n",
    "\n",
    "# Fill missing values in merged DataFrame with median values\n",
    "merged_df.fillna(median_values, inplace=True)\n",
    "print(merged_df.shape)\n",
    "merged_df\n",
    "\n",
    "X_train = final\n",
    "y_train = X_train.pop(item='Energy')\n",
    "\n",
    "X_test = merged_df\n",
    "X_test.pop(item=\"ID\")\n",
    "y_test = X_test.pop(item='Energy')\n",
    "\n",
    "# Create a Decision Tree Regressor model\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "submit['Energy'] = y_pred\n",
    "submit = submit[['ID', 'Energy']]\n",
    "submit.to_csv('SampleSubmission__23_.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
